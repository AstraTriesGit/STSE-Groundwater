---
title: "Combining Disjoint GWL Datasets"
output: pdf_document
---

Throughout the research process, we have acquired datasets from India-WRIS in the following order:
- May 2023 - May 2024
- May 2018 - May 2023
- May 2014 - May 2018
- May 2004 - May 2014 (6/9, TO BE RECEIVED)
```{r}
library(readxl)
library(dplyr)
library(purrr)
library(fs)
library(lobstr)
library(feather)
library(ggplot2)
library(tidyverse)
```

## Datatypes and `feather` Format Conversion
We read all the Excel files provided by India-WRIS and combined them into different `.feather` files depending
on the period and the measurement type (manual/telemetric.)
```{r}
# concatenate all Excel files in a period's telemetric folder
combine_telemetric <- function (excel_dir) {
  excel_files <- dir_ls(excel_dir, regexp = "\\.xlsx$")
  # concatenate the excel files
  combined <- excel_files %>%
    map_df(~ {
      data <- read_xlsx(.x)
      data %>% drop_na()
      return(data)
    })
  return (combined)
}

gwl_2023_24_telemetric <- combine_telemetric("data/CGWB_GWL_1-5-23_1-5-24/Telemetric")
write_feather(gwl_2023_24_telemetric, "data/combined/gwl_2023_24_telemetric.feather")

# changed datatype of station_code
col_spec <- rep("guess", 14)
col_spec[2] <- "text"
gwl_2023_24_manual <- read_xlsx("data/CGWB_GWL_1-5-23_1-5-24/Manual/9. Manual GWL_CGWB_1 May 2023 to 1 May 2023.xlsx",
                    col_types = col_spec)
write_feather(gwl_2023_24_manual, "data/combined/gwl_2023_24_manual.feather")

# warnings: expecting numeric got NULL, coercing text to numeric (NaN)
gwl_2018_23_telemetric <- combine_telemetric("data/GW Level Data 1 May 2018 to 1 May 2023/Telemetric Ground Water Level")
write_feather(gwl_2018_23_telemetric, "data/combined/gwl_2018_23_telemetric.feather")

gwl_2018_23_manual <- read_xlsx("data/GW Level Data 1 May 2018 to 1 May 2023/Manual Ground Water Level/Manual Ground water Level from 1 May 2018 to 1 May 2023.xlsx",)
write_feather(gwl_2018_23_manual, "data/combined/gwl_2018_23_manual.feather")

gwl_2014_18 <- read_csv("data/CGWB_GWL_DATA_MAY2014_MAY2018.csv")
write_feather(gwl_2014_18, "data/combined/gwl_2014_18.feather")
```
We have created 5 `.feather` files and will assess the structure of the data in each file separately.

## Analysis of Telemetric 2023-24 Data
```{r}
gwl_2023_24_telemetric <- read_feather("data/combined/gwl_2023_24_telemetric.feather")
glimpse(gwl_2023_24_telemetric)
```
Dimensions = 4,274,319 x 14
We take the time to note the datatypes here since we require their consistency as we plan to combine the five files.
For each file, we will observe the source of NA values.
```{r}
na_count <- gwl_2023_24_telemetric %>%
  summarise_all(~sum(is.na(.)))
glimpse(na_count)
```
Luckily enough, no NAs in any column. Moving on.

## Analysis of Manual 2023-24 Data
```{r}
gwl_2023_24_manual <- read_feather("data/combined/gwl_2023_24_manual.feather")
# glimpse(gwl_2023_24_manual) # confirmed to have the same schema
na_count <- gwl_2023_24_manual %>%
  summarise_all(~sum(is.na(.)))
glimpse(na_count)
```
Dimensions = 33,865 x 14
Once again, no NAs in any column. We will use `bind_rows()` to combine the last examined file.

## Analysis of Telemetric 2018-23 Data
```{r}
combined <- bind_rows(gwl_2023_24_telemetric, gwl_2023_24_manual)

gwl_2018_23_telemetric <- read_feather("data/combined/gwl_2018_23_telemetric.feather")
# glimpse(gwl_2018_23_telemetric) # confirmed to have the same schema
na_count <- gwl_2018_23_telemetric %>%
  summarise_all(~sum(is.na(.)))
glimpse(na_count)


```
Dimensions = 17,088,404 x 14
This is where our luck runs out, with 127k observations missing (latitude, longitude) readings, as well as some missing
values in `data_value`. For this version of the data pipeline, we are not going to attempt imputation and simply...drop
missing observations.
```{r}
gwl_2018_23_telemetric <- drop_na(gwl_2018_23_telemetric)
combined <- bind_rows(combined, gwl_2018_23_telemetric)
```

## Analysis of Manual 2018-23 Data
```{r}
gwl_2018_23_manual <- read_feather("data/combined/gwl_2018_23_manual.feather")
glimpse(gwl_2018_23_manual)
na_count <- gwl_2018_23_manual %>%
  summarise_all(~sum(is.na(.)))
glimpse(na_count)
```
Dimensions = 674,846 x 14
No NAs in data. However, (latitude, longitude) are strings. We have to convert them to doubles, but the numbers are
possibly too precise. Pending evaluation of null values.
```{r}
# this introduces NAs in the dataset
gwl_2018_23_manual <- gwl_2018_23_manual %>%
    mutate(latitude = as.double(latitude),
           longitude = as.double(longitude)) %>%
    drop_na()


```

## Analysis of 2014-18 Data
```{r}
combined <- bind_rows(combined, gwl_2018_23_manual)

gwl_2014_18 <- read_feather("data/combined/gwl_2014_18.feather")
glimpse(gwl_2014_18) # hmm
# also has NAs
```
Dimensions = 261,942 x 12
Evident issues with this table are:
- missing columns (concat, unit_code)
- extra columns (block_name)
- incompatible column names
  - station_name -> name
  - lattitude -> latitude
  - agency_name -> agency
  - state_name -> state
  - district_name -> district
  - tehsil_name -> tahsil
  - data_acquisition_time -> data_time
- incompatible datatypes with current schema (data_acquisition_time)

```{r}
gwl_2014_18 <- gwl_2014_18 %>%
        drop_na() %>%
        rename(name = station_name,
               latitude = lattitude,
               agency = agency_name,
               state = state_name,
               district = district_name,
               tahsil = tehsil_name,
               data_time = data_acquisition_time) %>%
        mutate(data_time = as.POSIXct(data_time, format = "%d-%b-%Y %H:%M"))
glimpse(gwl_2014_18)
```
`unit_code` is confirmed to have the value 'm' in all rows, implying all measurements are made with metres as the unit.
It is not expected that this changes with 2014-28. `concat` also does not hold any special information, so the two
columns can be dropped in the combined dataset.
We will also drop the `datatype_code` column in the combined dataset, as well as drop the `block_name` column in 2014-18.

```{r}
combined <- combined %>%
        select(-unit_code, -concat, -datatype_code)

gwl_2014_18 <- gwl_2014_18 %>%
        select(-block_name)

combined <- bind_rows(combined, gwl_2014_18) # success!
write_feather(combined, "data/combined/gwl.feather")

glimpse(gwl_2018_23_telemetric)
```
Now, we can use our GWL data!!...not quite. This file only solves the data engineering problem at the schema level.
Invalid values have not been fully dealt with, and handling these are beyond the capabilities of standard cleaning procedures.
In either case, now is a good time to write down our **data engineering assumptions** in case we wish to revisit the
process again.

```{r}
library(dplyr)

# restart here
gwl_2014_18 <- read_feather("data/combined/gwl_2014_18.feather")
gwl_2018_23_telemetric <- read_feather("data/combined/gwl_2018_23_telemetric.feather")
gwl_2018_23_manual <- read_feather("data/combined/gwl_2018_23_manual.feather")

gwl_2014_18 <- gwl_2014_18 %>%
  drop_na() %>%
  rename(name = station_name,
         latitude = lattitude,
         agency = agency_name,
         state = state_name,
         district = district_name,
         tahsil = tehsil_name,
         data_time = data_acquisition_time) %>%
  mutate(data_time = as.POSIXct(data_time, format = "%d-%b-%Y %H:%M"))

gwl_2018_23_manual <- gwl_2018_23_manual %>%
  mutate(latitude = as.double(latitude),
         longitude = as.double(longitude)) %>%
  drop_na()
# restart ends here


gwl_2014_18 <- gwl_2014_18 %>%
  distinct(latitude, longitude)
gwl_2018_23_telemetric <- gwl_2018_23_telemetric %>%
  distinct(latitude, longitude)
gwl_2018_23_manual <- gwl_2018_23_manual %>%
  distinct(latitude, longitude)

common <- inner_join(gwl_2018_23_telemetric, gwl_2014_18, by = c("latitude", "longitude"))

get_decimal_places <- function(x) {
  if (is.numeric(x)) {
    # Convert to character, handling potential scientific notation
    s <- format(x, scientific = FALSE)

    # Split the string at the decimal point
    parts <- strsplit(s, "\\.")[[1]]

    # If there's no decimal part, return 0
    if (length(parts) < 2) {
      return(0)
    } else {
      # Count the number of characters in the decimal part
      return(nchar(parts[2]))
    }
  } else {
    stop("Input must be numeric.")
  }
}



significant_digits <- gwl_2018_23_telemetric %>%
        mutate(latitude = as.integer(get_decimal_places(latitude)),
               longitude = as.integer(get_decimal_places(longitude))) %>%
        group_by(latitude, longitude) %>%
        summarise(count = n()) %>%
        arrange(count)

significant_digits_14 <- gwl_2014_18 %>%
  mutate(latitude = as.integer(get_decimal_places(latitude)),
         longitude = as.integer(get_decimal_places(longitude))) %>%
  group_by(latitude, longitude) %>%
  summarise(count = n()) %>%
        arrange(count)


significant_digits_18_manual <- gwl_2018_23_manual %>%
  mutate(latitude = as.integer(get_decimal_places(latitude)),
         longitude = as.integer(get_decimal_places(longitude))) %>%
  group_by(latitude, longitude) %>%
  summarise(count = n()) %>%
  arrange(count)
```


## Data Engineering Assumptions Made So Far (29/9)
- NAs can be safely ignored (gwl_2018_23_telemetric, gwl_2014_18)
- Coerced NAs can be safely ignored (gwl_2018_23_manual)
- Coordinates precision can be worked with (gwl_2018_23_manual)
- `unit_code` assumption: gwl_2014_18's `data_value` column can be understood to be in metres
- `concat` is a meaningless column and will not affect downstream analysis (it's just `station_code` with a hash?)
- `datatype_code` and `block_name`(gwl_2014_18) can be safely dropped without affecting downstream analysis
